
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">


  <title>MAGR 2019</title>

  <!--Open Graph Related Stuff-->
  <meta property="og:title" content="3D Scene Generation"/>
  <meta property="og:url" content="https://3dscenegen.github.io/"/>
  
  <meta property="og:image" content=""/>
  <meta property="og:image:url" content=""/>

  <!-- CSS  -->
	  
  <link href="css/bootstrap.min.css" rel="stylesheet" type="text/css">
  <link href="css/main.css" rel="stylesheet" type="text/css">
</head>

  <body>

    <!-- <div class="top-strip"></div> -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    
    <div class="navbar-header">
      <a class="navbar-brand" href="/"></a>
      <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>

    <div class="navbar-collapse collapse" id="navbar-main">
      <ul class="nav navbar-nav">
        <li><a href="#introduction">Introduction</a></li>
        <li><a href="#call-for-papers">Call for Papers</a></li>
        <li><a href="#important-dates">Important Dates</a></li>
        <li><a href="#schedule">Schedule</a></li>
        <li><a href="#accepted-papers">Accepted Papers</a></li>
        <li><a href="#organizers">Organizers</a></li>
      </ul>
    </div>

  </div>
</div>


    <div class="container">
      <div class="page-content">
          <p><br /></p>
<div class="row">
  <div class="col-xs-12">
    <center><h1><a href="#">Multi-Sensor for Action and Gesture Recognition (MAGR)</a></h1></center>
    <center><h2><a href="https://www.acpr2019.org/workshops.html">ACPR 2019 Workshop, Auckland, New Zealand</a></h2></center>
    <center>Tuesday November 26 2019</center>
  </div>
</div>

<hr />

<div class="row" id="intro">
  <div class="col-md-12">
    <img src="images/logo.png" />
  </div>
</div>

<p><br /></p>
<div id="introduction"></div>
<h2>Introduction</h2>

<div class="row">
  <div class="col-xs-12">
    <p><font face="New Times Roman">
      Besides traditional RGB camera and infrared camera, various new sensors have been invented and widely used for imaging in the past decade, such as depth sensor, event camera, thermal infrared camera, and doppler camera. Merging information from multiple sensors provides better visual effectiveness for applications in surveillance, smart homes, and human-machine interaction. And the accompanying vision and recognition problems have attracted great interests of researchers. Although significant progress has been achieved in recent years using new sensors, e.g., the Kinect sensors are widely used for human action recognition, the applications of the new sensors in computer vision and pattern recognition tasks still need further exploration. These sensors provide different types and viewpoints of visual information, however, many challenges still exist such as how to select and fuse multi-sensor information. The goal of this workshop is to disseminate recent research progress for researchers on a focused platform, discuss how the multi-sensor based methods can benefit the field of action and gesture recognition, and explore potential collaborations. 
    </p></font>
	
	
  </div>
</div>
<p><br /></p>
<div id="call-for-papers"></div>
<h2>Call for Papers</h2>

<div class="row">
  <div class="col-xs-12">
    <p>
		<font face="New Times Roman">
      <span style="font-weight:500;"><strong>Call for papers:</strong></span> Papers addressing action and gesture recognition with multiple sensors and related topics are invited. Both theoretical and application results are sought for. The topics include, but are not limited to:
    </p>
    <ul>
      <li>Action recognition from multi-sensors</li>
      <li>Gesture recognition from multi-sensors</li>
      <li>Multi-sensor feature extraction</li>
      <li>Multi-sensor feature evaluation</li>
      <li>Multi-sensor feature selection</li>
      <li>Multi-sensor feature fusion</li>
      <li>2D/3D Human pose estimation</li>
	  <li>2D/3D Hand pose estimation</li>
      <li>Facial activity analysis</li>
	  <li>Action/event detection for health care</li>
      <li>Action/event detection for human-machine interaction</li>
      <li>Transfer learning among data from different sensors</li>
      <li>Knowledge distillation between models learnt from different sensor data</li>
      <li>Relationship modeling among data from different sensors</li>
      <li>Cascade feature and multilayer classifier for action and gesture recognition</li>
      <li>Multi-sensor based depth images and dense trajectories</li>
	  <li>Improved combined feature representation for action and gesture recognition</li>
      <li>Multi-sensor collaboration in smart lighting control system</li>
    </ul>
    <p>
      <span style="font-weight:500;">Submission:</span> <a href="#" target="_blank" rel="noopener"><span style="color: #3366ff;">Click here for submission</span></a>
      <ul>
      <li>Submitted papers should not have been published, accepted or under review elsewhere. Non-peer reviewed media, such as Arxiv do not violate the terms.</li>
      <li>Submissions need to follow the single-blind policy and be formatted in LNCS style, with a maximum of 14 pages (including references).</li>
      <li>All the papers must be submitted using the provided templates.</li>
        <ul>
          <li><a href="ftp://ftp.springernature.com/cs-proceeding/llncs/llncs2e.zip"><span style="color: #3366ff;">LaTeX2e Proceedings Templates (zip)</span></a></li>
          <li><a href="https://www.overleaf.com/latex/templates/springer-lecture-notes-in-computer-science/kzwwpvhwnvfj#.WuA4JS5uZpi"><span style="color: #3366ff;">LaTeX2e Proceedings Templates - Overleaf</span></a></li>
         <li><a href="ftp://ftp.springernature.com/cs-proceeding/llncs/word/splnproc1703.zip"><span style="color: #3366ff;">Microsoft Word Proceedings Templates (zip)</span></a></li>
         <li><a href="https://resource-cms.springernature.com/springer-cms/rest/v1/content/7117506/data/v1"><span style="color: #3366ff;">Microsoft Word 2003 Proceedings Templates (zip)</span></a></li>
       </ul>
    </ul>      
    Workshop proceedings will be published after the conference in the CCIS series of Springer through the ACPR organizers (publication chair).
<br /><u>NOTE</u>: Registration for workshops is included in the conference registration, i.e., all the registered ACPR participants are free to attend any of the workshops (besides all the sessions of the main conference).
    </p>


	</font>
  </div>
</div>
<p><br /></p>
<div id="important-dates"></div>
<h2>Important Dates</h2>

<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Paper Submission Deadline</td>
          <td>September 10, 2019 (No Extension)</td>
        </tr>
        <tr>
          <td>Notification to Authors</td>
          <td>September 25, 2019</td>
        </tr>
        <tr>
          <td>Camera-Ready Deadline</td>
          <td>October 1, 2019</td>
        </tr>
        <tr>
          <td>Workshop Date</td>
          <td>November 26, 2019</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>
<p><br /></p>

<p><br /></p>
<div id="schedule"></div>
<h2>Schedule</h2>
<div class="row">
  <div class="col-md-12">
  TBD
  </div>
</div>



<p><br /></p>
<div id="accepted-papers"></div>
<h2>Accepted Papers</h2>
<div class="row">
  <div class="col-md-12">
  TBD
  </div>
</div>

<p><br /></p>
<div id="organizers"></div>
<h2>Organizers</h2>

<div class="row">



  <div class="col-xs-2">
    <a href="#">
      <center><img class="people-pic" src="images/tzg.jpg" /></center>
    </a>
    <div class="people-name">
      <a href="#">Zhigang Tu, Ph.D. </a>
      <h6>State Key Laboratory of Information Engineering in Surveying, Mapping and Remote sensing
Wuhan University, Wuhan, China<br><strong>E-mail:</strong> tuzhigang@whu.edu.cn
</h6>
    </div>
  </div>
  
  <div class="col-xs-2">
    <a href="#">
      <center><img class="people-pic" src="images/yjy.jpg" /></center>
    </a>
    <div class="people-name">
      <a href="#">Jianyu Yang, Ph.D.</a>
      <h6>Soochow University, Suzhou, China<br><strong>E-mail:</strong> jyyang@suda.edu.cn</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="#">
      <center></cen><img class="people-pic" src="images/mjj.jpg" /></center>
    </a>
    <div class="people-name">
      <a href="#">JingJing Meng, Ph.D.</a>
      <h6>Computer Science and Engineering Department<br>University at Buffalo, State University of New York (SUNY), USA<br><strong>Email:</strong> jmeng2@buffalo.edu
</h6>
    </div>
  </div>

</div>

<p><br /></p>
<div id="technical-program-committee-tpc"></div>
<h3>Technical Program Committee (TPC)</h3>

<ul>
<li><strong>Shizheng Wang</strong>, Institute of Microelectronics, Chinese Academy of Sciences, China</li>    
<li><strong>Yang Xiao</strong>, Huazhong University of Science and Technology, China</li>    
<li><strong>Sreyasee Das Bhattacharjee</strong>, University of North Carolina, Charlotte, USA</li>  
<li><strong>Junwu Weng</strong>, Nanyang Technological University, Singapore</li>  
<li><strong>Hongxing Wang</strong>, Chongqing University, China</li>  
<li><strong>Ye Luo</strong>, Tongji University, China</li>  
<li><strong>Yuning Jiang</strong>, Beijing Bytedance Technology Co., Ltd., China</li>  
<li><strong>Hui Liang</strong>, Amazon Co., Ltd., USA</li>  
<li><strong>Mengyuan Liu</strong>, Nanyang Technological University, Singapore</li>  
<li><strong>Gang Yu</strong>, Beijing Megvii Co., Ltd., China</li>  
<li><strong>Chaoqun Weng</strong>, Momenta Co., Ltd., China1</li>
<li><strong>Tan Yu</strong>, Nanyang Technological University, Singapore</li>
<li><strong>Yuwei Wu</strong>, Beijing Institute of Technology, China</li>
<li><strong>Zhou Ren</strong>, Wormpex AI Research LLC, USA</li>
<li><strong>Dejun Zhang</strong>, China University of Geosciences, Wuhan, China</li>
</ul>

<hr />

<div class="row">
  <div class="col-xs-12">
    <h2>Acknowledgments</h2>
  </div>
</div>
<p><a name="/acknowledgements"></a></p>
<div class="row">
  <div class="col-xs-12">
    <p>
      This workshop is proudly sponsored by RapidV++ (Shenzhen), MEGVII, CIT-China, and DeepMicro.
    </p>
  </div>
</div>
<div class="row">
  <div class="col-md-4">
    <a href="#"><img src="images/01.png" /></a>
	<a href="#"><img src="images/02.jpg" /></a>
	<a href="#"><img src="images/03.png" /></a>
  </div>
  
</div>
<p><br /></p>


      </div>
    </div>

  </body>
</html>
